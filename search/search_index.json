{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Python Enzyme Engineering Database","text":"<p>API under construction \ud83c\udfd7\ufe0f</p> <p>The API is currently under construction and is subject to change.</p>"},{"location":"#what-is-pyeed","title":"\ud83e\udd14 What is pyeed?","text":"<p><code>pyeed</code> is a Python toolkit for creating Protein and or Nucleotide knowledge graphs for bioinformatic analysis. The knowledge graph is based on the pyeed graph model, structuring Protein and Nucleotide sequences, annotations, and metadata in a Neo4j graph database. pyeed enables seamless data integration of various bioinformatic data sources, such as UniProt and NCBI. Besides the graph model, Python provides a set of tools for sequence analysis, such as sequence alignment or calculation of sequence embeddings.</p>"},{"location":"#pyeed-graph-model","title":"\ud83d\udcdd pyeed graph model","text":"<p>The pyeed graph model offers a structure for organizing sequences of proteins and nucleotides and their annotations and metadata. Sequence annotations can describe regions or individual sites of a sequence, such as active sites, binding sites, or domains. Furthermore, the graph model contains information on the sequence's source and Gene Ontology terms of the sequence.</p> <p></p>"},{"location":"api/clustalo/","title":"Clustalo","text":"<pre><code>options:\n  show_source: false\n</code></pre>"},{"location":"api/dbconnect/","title":"DatabaseConnector","text":""},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.node_properties","title":"<code>node_properties</code>  <code>property</code>","text":"<p>Returns a list of dictionaries containing the node labels and their properties.</p>"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.relationship_properties","title":"<code>relationship_properties</code>  <code>property</code>","text":"<p>Returns a list of dictionaries containing the relationship types and their properties.</p>"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.relationships","title":"<code>relationships</code>  <code>property</code>","text":"<p>Returns a list of dictionaries containing the source node label, relationship type, and target node label.</p>"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.close","title":"<code>close()</code>","text":"<p>Closes the connection to the Neo4j database.</p>"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.constraints_exist","title":"<code>constraints_exist()</code>","text":"<p>Check and if constraints exist in the database. Return True if constraints exist.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if constraints exist in the database, False otherwise.</p>"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.execute_read","title":"<code>execute_read(query, parameters=None)</code>","text":"<p>Executes a read (MATCH) query using the Neo4j driver.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The Cypher query to execute.</p> required <code>parameters</code> <code>dict</code> <p>A dictionary of parameters to pass to the query.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>list[dict]: The result of the query as a list of dictionaries.</p>"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.execute_write","title":"<code>execute_write(query, parameters=None)</code>","text":"<p>Executes a write (CREATE, DELETE, etc.) query using the Neo4j driver.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The Cypher query to execute.</p> required <code>parameters</code> <code>dict</code> <p>A dictionary of parameters to pass to the query.</p> <code>None</code>"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.generate_model_diagram","title":"<code>generate_model_diagram(models_path='pyeed/model.py')</code>","text":"<p>Generates a arrows json file representing the model diagram.</p> <p>Parameters:</p> Name Type Description Default <code>models_path</code> <code>str</code> <p>The path to the models file. Defaults to \"pyeed/model.py\".</p> <code>'pyeed/model.py'</code>"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.initialize_db_constraints","title":"<code>initialize_db_constraints(user, password, models_path='model.py')</code>","text":"<p>Run the neomodel_install_labels script to set up indexes and constraints on labels of Object-Graph Mapping (OGM) models.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>The username for the Neo4j database.</p> required <code>password</code> <code>str</code> <p>The password for the Neo4j database.</p> required <code>models_path</code> <code>str</code> <p>The path to the models file. Defaults to \"model.py\".</p> <code>'model.py'</code>"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.remove_db_constraints","title":"<code>remove_db_constraints(user, password)</code>","text":"<p>Run the neomodel_remove_labels script to drop all indexes and constraints from labels in the Neo4j database.</p> <p>Parameters:</p> Name Type Description Default <code>user</code> <code>str</code> <p>The username for the Neo4j database.</p> required <code>password</code> <code>str</code> <p>The password for the Neo4j database</p> required"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.stats","title":"<code>stats()</code>","text":"<p>Returns the number of nodes and relationships in the database.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, int]</code> <p>The number of nodes and relationships in the database.</p>"},{"location":"api/dbconnect/#pyeed.dbconnect.DatabaseConnector.wipe_database","title":"<code>wipe_database(date=None)</code>","text":"<p>Deletes all nodes and relationships in the database. The date parameter can be used but is not necessary. When not provided, all data will be deleted. If provided, the data will only be deleted if the date matches the current date. The format of the date should be 'YYYY-MM-DD'.</p>"},{"location":"api/primarydbadapter/","title":"PrimaryDBAdapter","text":"<p>               Bases: <code>Generic[T]</code></p> <p>Orchestrates asynchronous HTTP GET requests to a primary sequence database. It uses an injected mapper (data_mapper) to process responses and save data.</p>"},{"location":"api/primarydbadapter/#pyeed.adapter.primary_db_adapter.PrimaryDBAdapter.execute_requests","title":"<code>execute_requests()</code>  <code>async</code>","text":"<p>Executes the asynchronous HTTP GET requests concurrently.</p>"},{"location":"api/pyeed/","title":"Pyeed","text":"<p>Main class to interact with the pyeed graph database.</p>"},{"location":"api/pyeed/#pyeed.main.Pyeed.calculate_sequence_embeddings","title":"<code>calculate_sequence_embeddings(batch_size=16, model_name='facebook/esm2_t33_650M_UR50D', num_gpus=1, embedding_type='final_embeddings')</code>","text":"<p>Calculates embeddings for all sequences in the database that do not have embeddings, using the new EmbeddingProcessor with automatic device management.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Number of sequences to process in each batch.</p> <code>16</code> <code>model_name</code> <code>str</code> <p>Model used for calculating embeddings.</p> <code>'facebook/esm2_t33_650M_UR50D'</code> <code>num_gpus</code> <code>int</code> <p>Number of GPUs to use. If None, use all available GPUs.</p> <code>1</code> <code>embedding_type</code> <code>str</code> <p>Type of embedding to calculate (\"last_hidden_state\", \"all_layers\", \"first_layer\", \"final_embeddings\").</p> <code>'final_embeddings'</code>"},{"location":"api/pyeed/#pyeed.main.Pyeed.calculate_single_sequence_embedding","title":"<code>calculate_single_sequence_embedding(sequence, model_name='facebook/esm2_t33_650M_UR50D', embedding_type='last_hidden_state')</code>","text":"<p>Calculate embedding for a single protein sequence.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>str</code> <p>Protein sequence string</p> required <code>model_name</code> <code>str</code> <p>Model to use for embedding calculation</p> <code>'facebook/esm2_t33_650M_UR50D'</code> <code>embedding_type</code> <code>Literal['last_hidden_state', 'all_layers', 'first_layer', 'final_embeddings']</code> <p>Type of embedding to calculate</p> <code>'last_hidden_state'</code> <p>Returns:</p> Type Description <code>Any</code> <p>Numpy array containing the embedding</p>"},{"location":"api/pyeed/#pyeed.main.Pyeed.chat","title":"<code>chat(question, openai_key, retry=False)</code>","text":"<p>Query the database using natural language via OpenAI's GPT-4 model.</p> <p>Parameters:</p> Name Type Description Default <code>question</code> <code>str</code> <p>Question to ask the database.</p> required <code>openai_key</code> <code>str</code> <p>OpenAI API key.</p> required <code>retry</code> <code>bool</code> <p>Whether to retry once if the query if it fails. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>list[dict]: List of responses from the database.</p>"},{"location":"api/pyeed/#pyeed.main.Pyeed.create_coding_sequences_regions","title":"<code>create_coding_sequences_regions()</code>","text":"<p>Creates coding sequences regions for all proteins in the database.</p> <p>It finds the nucleotide start and end positions and create a Region object for the corresponding DNA sequence. Create the region object with the right annotation. And then connect it to the DNA sequence.</p>"},{"location":"api/pyeed/#pyeed.main.Pyeed.database_id_mapper","title":"<code>database_id_mapper(ids, file)</code>","text":"<p>Maps IDs from one database to another using the UniProt ID mapping service</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[str]</code> <p>List of IDs to map.</p> required"},{"location":"api/pyeed/#pyeed.main.Pyeed.fetch_dna_entries_for_proteins","title":"<code>fetch_dna_entries_for_proteins(ids=None)</code>","text":"<p>Fetches DNA sequences for proteins that have a nucleotide id, set in the database. The fetching is done from NCBI nucleotide database in batches.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[str]</code> <p>List of protein IDs to fetch DNA sequences for. Defaults to None.</p> <code>None</code>"},{"location":"api/pyeed/#pyeed.main.Pyeed.fetch_from_primary_db","title":"<code>fetch_from_primary_db(ids, db)</code>","text":"<p>Fetches sequences and corresponding annotations from primary sequence databases and adds them to local database.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[str]</code> <p>List of sequence IDs to fetch from the primary database.</p> required <code>db</code> <code>str</code> <p>Name of the primary database to fetch from. Options are \"uniprot\", \"ncbi_protein\", and \"ncbi_nucleotide\".</p> required"},{"location":"api/pyeed/#pyeed.main.Pyeed.fetch_ncbi_nucleotide","title":"<code>fetch_ncbi_nucleotide(ids)</code>","text":"<p>Fetches nucleotide sequences from NCBI and adds them to the local database.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[str]</code> <p>List of nucleotide IDs to fetch from NCBI.</p> required"},{"location":"api/pyeed/#pyeed.main.Pyeed.fetch_ncbi_protein","title":"<code>fetch_ncbi_protein(ids)</code>","text":"<p>Fetches protein sequences from NCBI and adds them to the local database.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[str]</code> <p>List of protein IDs to fetch from NCBI.</p> required"},{"location":"api/pyeed/#pyeed.main.Pyeed.fetch_uniprot","title":"<code>fetch_uniprot(ids)</code>","text":"<p>Fetches protein sequences from UniProt and adds them to the local database.</p>"},{"location":"api/pyeed/#pyeed.main.Pyeed.get_available_devices","title":"<code>get_available_devices()</code>","text":"<p>Get list of available devices for embedding computation.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of available device names</p>"},{"location":"api/pyeed/#pyeed.main.Pyeed.get_dnas","title":"<code>get_dnas(accession_ids)</code>","text":"<p>Fetches a DNA sequence from the database by accession ID.</p> <p>Parameters:</p> Name Type Description Default <code>accession_ids</code> <code>list[str]</code> <p>List of DNA sequence accession IDs to fetch.</p> required"},{"location":"api/pyeed/#pyeed.main.Pyeed.get_proteins","title":"<code>get_proteins(accession_ids)</code>","text":"<p>Fetches a protein from the database by accession ID.</p>"},{"location":"setup/database/","title":"Neo4j Database","text":"<p><code>pyeed</code> needs a database to store sequence data and analysis results. The database can be set up locally or on a hosted server.</p>"},{"location":"setup/database/#local-setup","title":"Local Setup","text":"<p>Docker can be used to set up a local Neo4j database. The following bash configures and starts a Neo4j database in a Docker container. The authentication and data directories can be adjusted.</p> <pre><code>docker run -it --name pyeed-neo4j \\\n  --user=\"$(id -u):$(id -g)\" \\\n  -e NEO4J_AUTH=neo4j/12345678 \\\n  -p 7474:7474 \\\n  -p 7687:7687 \\\n  -v $HOME/Documents/db/data:/data \\\n  -v $HOME/Documents/db/logs:/logs \\\n  -v $HOME/Documents/db/import:/var/lib/neo4j/import \\\n  -v $HOME/Documents/db/plugins:/plugins \\\n  -e NEO4J_PLUGINS='[\"graph-data-science\", \"apoc\"]' \\\n  -e NEO4J_dbms_security_procedures_unrestricted=\"gds.*,apoc.*,gds.util.*\" \\\n  -d neo4j:latest\n</code></pre> <p>This script configures the Neo4j database with enabled graph data science and apoc plugins.</p>"},{"location":"setup/database/#hosted-setup","title":"Hosted Setup","text":"<p>Neo4j offers a free tier hosted database. If the free hosted database is inactive for a certain period, it will be deleted. To avoid data loss, it is recommended to back up the database regularly, use a local database, or upgrade to a paid plan.</p>"},{"location":"setup/docker/","title":"Docker","text":""},{"location":"setup/docker/#concept","title":"Concept","text":"<p>The PyEED Docker Service combines the PyEED toolkit with JupyterLab, a web-based editor for writing and executing Jupyter Notebooks with analysis tools. In combination, the <code>pyeed</code> package can be used from inside JupyterLab, whereas the setup and configuration of the analysis tools are taken care of by the Docker Service(1). In this way, the Docker Service allows you to run JupyterLab on your local machine without having to install Python, Jupyter, and the necessary Python tools to work with your data.</p> <ol> <li>Docker is a way to run software in a container. This means that the software is isolated from the rest of your system. This simplifies the installation of computing environments since everything is preconfigured in the container. Docker is comparable to running a virtual machine, but instead of installing a whole operating system, it only installs the software you need.</li> </ol> <p>To install Docker, follow the instructions for your operating system on the Docker website.</p>"},{"location":"setup/docker/#initial-setup","title":"Initial Setup","text":"<ol> <li> <p>Install Docker: Follow the instructions for your operating system on the Docker website.</p> </li> <li> <p>Download the PyEED Docker Service</p> </li> <li> <p>Start the Service by running the following steps:</p> </li> </ol> WindowsMacOS/Linux <ol> <li> <p>Open the command line by pressing Win+R and type <code>powershell</code>.</p> </li> <li> <p>Navigate to the Downloads folder and unzip the downloaded file.</p> </li> <li> <p>Navigate to the unzipped folder by running the following command, adjust the path if necessary:     <pre><code>cd ~\\Downloads\\pyeed-main\n</code></pre></p> </li> <li>Start the Docker Service by running the following command:     <pre><code>docker compose up --build\n</code></pre></li> </ol> <ol> <li>Open the terminal</li> <li>Navigate to the Downloads folder and unzip the downloaded file.     <pre><code>cd ~/Downloads\nunzip pyeed-main.zip\n</code></pre></li> <li>Navigate to the unzipped folder by running the following command, adjust the path if necessary:     <pre><code>cd ~/Downloads/pyeed-main\n</code></pre></li> <li>Start the Docker Service by running the following command:     <pre><code>docker compose up --build\n</code></pre></li> </ol>"},{"location":"setup/docker/#start-the-pyeed-docker-service","title":"Start the PyEED Docker Service","text":"<p>After the initial setup, all containers belonging to the PyEED Docker Service are created and started. The service is now added to the <code>Containers</code> section in the Docker Desktop application. To start the service, click on the  button next to the <code>pyeed</code> container. To access the JupyterLab environment, click on the link <code>8888:8888</code> in the header of the container. This will open a new tab in your browser, showing the JupyterLab environment.</p>"},{"location":"setup/docker/#stopping-the-pyeed-docker-service","title":"Stopping the PyEED Docker Service","text":"<p>To stop the service, navigate to the <code>Containers</code> section in the Docker Desktop application and click on the  button next to the <code>pyeed</code> container. Running containers are symbolized by a green container icon. You can close the browser window whenever you want. The container will keep running in the background unless you stop it in the Docker Desktop app.</p>"},{"location":"setup/jupyterlab/","title":"Setting up JupyterLab","text":"<p>What is JupyterLab?</p> <p>JupyterLab is a web-based editor for writing and executing Jupyter Notebooks. Additionally, it allows you to see the file system, terminal, and other tools in the same window.</p>"},{"location":"setup/jupyterlab/#initial-setup","title":"Initial Setup","text":"<ol> <li> <p>Install Docker</p> </li> <li> <p>Open the Docker Desktop application search for <code>haeussma/pyeed-notebook</code> in the upper search bar and click on <code>Pull</code>.</p> <p>}</p> </li> <li> <p>Navigate to the <code>Images</code> section in the Docker Desktop application and click on  next to the <code>haeussma/pyeed-notebook</code> image.     A <code>Run a new container</code> window pops up. Click on <code>Optional settings</code> to configure the container with the following settings:</p> <code>Container name</code> Container name: <code>PyEED-Lab</code> <code>Ports</code> Host port: <code>8888</code> <p><code>Volumes</code> </p> <p>Why specify a volume?</p> <p>The volume is used to define what directory of your local machine is visible to the container. Without this configuration, the container would not be able to access your local files. It is advised to make the directory in which you store your data for analysis.</p> Host path: <code>{SELECT YOUR WORKING DIRECTORY}</code> Container path: <code>/home/jovyan/work</code> Example <p></p> <p>Then, click on <code>Run</code>. The initial configuration process for the container might take a few seconds up to five minutes.</p> </li> <li> <p>Click on the link <code>8888:8888</code> in the header of the container. This will open a new tab in your browser, showing the JupyterLab environment.</p> <p></p> </li> <li> <p>\ud83c\udf89 You are now in the JupyterLab environment. Your local files can be accessed via the <code>work</code> folder.</p> </li> </ol>"},{"location":"setup/jupyterlab/#stopping-the-container","title":"Stopping the Container","text":"<p>To start the container, navigate to the <code>Containers</code> section in the Docker Desktop application and click on the  button next to the <code>PyEED-Lab</code> container. Running containers are symbolized by a green container icon. You can close the browser window whenever you want. The container will keep running in the background unless you stop it in the Docker Desktop app.</p>"},{"location":"setup/jupyterlab/#restarting-the-container","title":"Restarting the Container","text":"<p>To start the container, navigate to the <code>Containers</code> section in the Docker Desktop application and click on the  button next to the <code>PyEED-Lab</code> container. Then click on the blue port number <code>8888:8888</code> next to the start button.</p>"},{"location":"setup/setup_local_blast/","title":"Setup a Local BLAST Database","text":"<p>A local blast can be set up enabling faster searches. In the following, the clustered nr protein database from NCBI will be installed locally. Therefore, at least 250 GB of free disk space is required.</p> <ol> <li>Download the clustered <code>.fasta</code> sequences.</li> <li>Create a folder in the location where you want to store the database.</li> <li>Unzip the downloaded file and move the <code>.fasta</code> files to the created folder.</li> <li>Search for <code>haeussma/blast</code> in the search bar of the Docker Desktop application and click on <code>Pull</code>.</li> </ol>"},{"location":"usage/basics/","title":"Basis","text":"In\u00a0[\u00a0]: Copied! <pre>from pyeed import Pyeed\n\nuri = \"bolt://127.0.0.1:7687\"\nuser = \"neo4j\"\npassword = \"12345678\"\n\n# Create a Pyeed object, automatically connecting to the database\needb = Pyeed(uri, user, password)\n\n\n# UniProt IDs of proteins to be fetched from primary database\nids = [\n    \"P04182\",\n    \"Q6QDP7\",\n    \"P04182\",\n    \"P29758\",\n    \"A0A1G4JJF2\",\n    \"G8ZTZ5\",\n    \"A0A1G4MBD6\",\n    \"A0A7H9HSJ3\",\n    \"J7SA96\",\n    \"G0VK69\",\n]\n\n# Fetch proteins from primary database\needb.fetch_from_primary_db(ids)\n\n# number of nodes and edges in db\nprint(eedb.db.stats())\n</pre> from pyeed import Pyeed  uri = \"bolt://127.0.0.1:7687\" user = \"neo4j\" password = \"12345678\"  # Create a Pyeed object, automatically connecting to the database eedb = Pyeed(uri, user, password)   # UniProt IDs of proteins to be fetched from primary database ids = [     \"P04182\",     \"Q6QDP7\",     \"P04182\",     \"P29758\",     \"A0A1G4JJF2\",     \"G8ZTZ5\",     \"A0A1G4MBD6\",     \"A0A7H9HSJ3\",     \"J7SA96\",     \"G0VK69\", ]  # Fetch proteins from primary database eedb.fetch_from_primary_db(ids)  # number of nodes and edges in db print(eedb.db.stats()) In\u00a0[\u00a0]: Copied! <pre># Calculate embeddings for all sequences in the database\needb.calculate_sequence_embeddings()\n</pre> # Calculate embeddings for all sequences in the database eedb.calculate_sequence_embeddings() In\u00a0[4]: Copied! <pre>from pyeed.model import Protein\n\n## Query using pyeed graph objects\n# Get all proteins\nproteins = Protein.nodes.all()\nprint(\"Number of proteins in database: \", len(proteins))\n\n# Get protein with id P04182\nprotein = Protein.nodes.get(accession_id=\"P04182\")\nprint(\n    f\"id: {protein.accession_id} | mol weight: {protein.mol_weight} | ec: {protein.ec_number} | seq length: {protein.seq_length}\"\n)\n\n## Or execute cypher query\n# Get all organisms that have at least one connected proteins\nquery = \"\"\"\nMATCH (o:Organism)&lt;-[:ORIGINATES_FROM]-(p:Protein)\nWITH o, COUNT(p) AS proteinCount\nWHERE proteinCount &gt;= 1\nRETURN o\n\"\"\"\n\norganisms = eedb.db.execute_read(query)\nprint(\"Number of organisms with at least one protein: \", len(organisms))\n\n# Get 5 most similar proteins to protein with accession_id P04182 based on sequence embedding\nquery = \"\"\"\nMATCH (p:Protein {accession_id: 'P04182'})\nCALL db.index.vector.queryNodes('vector_index_Protein_embedding', 5, p.embedding)\nYIELD node AS similarProtein, score\nRETURN similarProtein.accession_id AS accession_id, \n       similarProtein.name AS protein_name, \n       score\nORDER BY score DESC\n\"\"\"\n\nsimilar_proteins = eedb.db.execute_read(query)\nsimilar_proteins\n</pre> from pyeed.model import Protein  ## Query using pyeed graph objects # Get all proteins proteins = Protein.nodes.all() print(\"Number of proteins in database: \", len(proteins))  # Get protein with id P04182 protein = Protein.nodes.get(accession_id=\"P04182\") print(     f\"id: {protein.accession_id} | mol weight: {protein.mol_weight} | ec: {protein.ec_number} | seq length: {protein.seq_length}\" )  ## Or execute cypher query # Get all organisms that have at least one connected proteins query = \"\"\" MATCH (o:Organism)&lt;-[:ORIGINATES_FROM]-(p:Protein) WITH o, COUNT(p) AS proteinCount WHERE proteinCount &gt;= 1 RETURN o \"\"\"  organisms = eedb.db.execute_read(query) print(\"Number of organisms with at least one protein: \", len(organisms))  # Get 5 most similar proteins to protein with accession_id P04182 based on sequence embedding query = \"\"\" MATCH (p:Protein {accession_id: 'P04182'}) CALL db.index.vector.queryNodes('vector_index_Protein_embedding', 5, p.embedding) YIELD node AS similarProtein, score RETURN similarProtein.accession_id AS accession_id,         similarProtein.name AS protein_name,         score ORDER BY score DESC \"\"\"  similar_proteins = eedb.db.execute_read(query) similar_proteins <pre>Number of proteins in database:  44\nid: P04182 | mol weight: 48333.0 | ec: 2.6.1.13 | seq length: 439\nNumber of proteins associated with GO:0005739:  11\nNumber of organisms with at least two proteins:  9\n</pre> In\u00a0[\u00a0]: Copied! <pre>my_protein = Protein(\n    accession_id=\"12345!\",\n    name=\"my_protein\",\n    seq=\"MYAYAYAYA\",\n    seq_length=9,\n    mol_weight=2,\n)\n\nmy_protein.save()\n</pre> my_protein = Protein(     accession_id=\"12345!\",     name=\"my_protein\",     seq=\"MYAYAYAYA\",     seq_length=9,     mol_weight=2, )  my_protein.save() In\u00a0[8]: Copied! <pre># Close the connection to the database\needb.db.close()\n</pre> # Close the connection to the database eedb.db.close() <pre>\ud83d\udd0c Connection closed.\n</pre>"},{"location":"usage/basics/#basis","title":"Basis\u00b6","text":""},{"location":"usage/basics/#query-primary-databases","title":"Query Primary databases\u00b6","text":"<p><code>pyeed</code> has a set of build in query methods which allow retrieving data from the primary databases such as UniProt and NCBI. Using the <code>fetch_from_primary_db</code> or <code>fetch_nucleotide_from_db</code> methods, either protein or nucleotide sequences can be retrieved from the primary databases. Besides the sequence, also Gene Ontology, Organism, region, and site annotations are retrieved and added to the database as defined in the <code>pyeed</code> graph model.</p>"},{"location":"usage/basics/#sequence-embeddings","title":"Sequence embeddings\u00b6","text":"<p>The sequence embeddings are generated using Meta's <code>ESM2</code> (esm2_t33_650M_UR50D) model. By default, embeddings are calculated in batches of 16 sequences and subsequently added to the database after the calculation.</p>"},{"location":"usage/basics/#visualize-whats-in-the-db","title":"Visualize what's in the DB\u00b6","text":"<p>To use the web interface, open a browser and go to <code>http://localhost:7474/</code>.</p>"},{"location":"usage/basics/#query-db","title":"Query DB\u00b6","text":""},{"location":"usage/basics/#manually-add-a-protein-to-the-db","title":"Manually add a Protein to the DB\u00b6","text":"<p>Besides automatically fetching data from the primary databases, it is also possible to manually add a protein to the database. This can be done by creating a <code>Protein</code> object and adding it to the database.</p> <p>For more examples on query and adding data to the database, refere to the <code>neomodel</code> documentation.</p>"},{"location":"usage/blast/","title":"BLAST Search","text":"In\u00a0[1]: Copied! <pre># change log level to INFO\nimport sys\n\nfrom loguru import logger\n\nlogger.remove()\nlevel = logger.add(sys.stderr, level=\"WARNING\")\n</pre> # change log level to INFO import sys  from loguru import logger  logger.remove() level = logger.add(sys.stderr, level=\"WARNING\") In\u00a0[2]: Copied! <pre>from pyeed.tools import Blast\n\n# Example protein sequence\nsequence = \"MSEQVAAVAKLRAKASEAAKEAKAREAAKKLAEAAKKAKAKEAAKRAEAKLAEKAKAAKRAEAKAAKEAKRAAAKRAEAKLAEKAKAAK\"\n\n# Initialize BLAST search\nblast = Blast(\n    # service_url=\"http://localhost:6001/blast\",\n    mode=\"blastp\",  # Use blastp for protein sequences\n    db_path=\"/usr/local/bin/data/test_db\",  # Path in Docker container\n    db_name=\"protein_db\",  # Name of your BLAST database\n    evalue=0.1,  # E-value threshold\n    max_target_seqs=10,  # Maximum number of hits to return\n)\n\n# Perform search\nresults = blast.search(sequence)\nresults\n</pre> from pyeed.tools import Blast  # Example protein sequence sequence = \"MSEQVAAVAKLRAKASEAAKEAKAREAAKKLAEAAKKAKAKEAAKRAEAKLAEKAKAAKRAEAKAAKEAKRAAAKRAEAKLAEKAKAAK\"  # Initialize BLAST search blast = Blast(     # service_url=\"http://localhost:6001/blast\",     mode=\"blastp\",  # Use blastp for protein sequences     db_path=\"/usr/local/bin/data/test_db\",  # Path in Docker container     db_name=\"protein_db\",  # Name of your BLAST database     evalue=0.1,  # E-value threshold     max_target_seqs=10,  # Maximum number of hits to return )  # Perform search results = blast.search(sequence) results Out[2]: subject_id identity alignment_length mismatches gap_opens query_start query_end subject_start subject_end evalue bit_score 0 seq7 81.818 22 3 1 31 51 11 32 0.003 22.3 1 seq1 100.000 25 0 0 1 25 1 25 0.004 22.3 2 seq2 61.538 26 10 0 20 45 5 30 0.038 19.2 <p>The results are returned as a pandas DataFrame with the following columns:</p> <ul> <li>subject_id: ID of the matched sequence</li> <li>identity: Percentage identity</li> <li>alignment_length: Length of the alignment</li> <li>mismatches: Number of mismatches</li> <li>gap_opens: Number of gap openings</li> <li>query_start/end: Start/end positions in query sequence</li> <li>subject_start/end: Start/end positions in subject sequence</li> <li>evalue: Expectation value</li> <li>bit_score: Bit score</li> </ul> <pre># For protein sequences\nmakeblastdb -in proteins.fasta -dbtype prot -out blast_db/my_proteins\n\n# For nucleotide sequences\nmakeblastdb -in nucleotides.fasta -dbtype nucl -out blast_db/my_nucleotides\n</pre> <p>To access the BLAST Docker container shell and create databases:</p> <pre># Enter the BLAST container shell\ndocker compose exec blast bash\n# \n# Navigate to database directory\ncd /usr/local/bin/data/blast_db\n# \n# Create protein database\nmakeblastdb -in proteins.fasta -dbtype prot -out my_proteins\n# \n# Create nucleotide database \nmakeblastdb -in nucleotides.fasta -dbtype nucl -out my_nucleotides\n</pre> <p>Make sure your FASTA files are mounted in the container's <code>/usr/local/bin/data/blast_db</code> directory.</p> In\u00a0[3]: Copied! <pre># Configure BLAST for sensitive protein search\nblast = Blast(\n    # service_url=\"http://localhost:6001/blast\",\n    mode=\"blastp\",\n    db_path=\"/usr/local/bin/data/test_db\",\n    db_name=\"protein_db\",\n    evalue=1e-1,  # More stringent E-value\n    max_target_seqs=100,  # Return more hits\n    num_threads=4,  # Use 4 CPU threads\n)\n\n# Search with longer timeout\nresults = blast.search(sequence, timeout=7200)  # 2 hour timeout\n\n# Filter results\nsignificant_hits = results[results[\"identity\"] &gt; 80]  # Only hits with &gt;90% identity\nsignificant_hits\n</pre> # Configure BLAST for sensitive protein search blast = Blast(     # service_url=\"http://localhost:6001/blast\",     mode=\"blastp\",     db_path=\"/usr/local/bin/data/test_db\",     db_name=\"protein_db\",     evalue=1e-1,  # More stringent E-value     max_target_seqs=100,  # Return more hits     num_threads=4,  # Use 4 CPU threads )  # Search with longer timeout results = blast.search(sequence, timeout=7200)  # 2 hour timeout  # Filter results significant_hits = results[results[\"identity\"] &gt; 80]  # Only hits with &gt;90% identity significant_hits Out[3]: subject_id identity alignment_length mismatches gap_opens query_start query_end subject_start subject_end evalue bit_score 0 seq7 81.818 22 3 1 31 51 11 32 0.003 22.3 1 seq1 100.000 25 0 0 1 25 1 25 0.004 22.3 <p>Thereafter, the ids of the hits can be added to the pyeed database, using the <code>fetch_from_primary_db</code> function.</p>"},{"location":"usage/blast/#blast-search","title":"BLAST Search\u00b6","text":""},{"location":"usage/blast/#setup","title":"Setup\u00b6","text":"<p>The BLAST service runs in a Docker container and requires:</p> <ol> <li>A local BLAST database</li> <li>The Docker service running</li> </ol>"},{"location":"usage/blast/#basic-usage","title":"Basic Usage\u00b6","text":"<p>The <code>Blast</code> class provides an interface to search protein or nucleotide sequences against a local BLAST database.</p>"},{"location":"usage/blast/#creating-a-blast-database","title":"Creating a BLAST Database\u00b6","text":"<p>Before using BLAST, you need to create a local database. Here's how to create one from a FASTA file:</p>"},{"location":"usage/blast/#advanced-usage","title":"Advanced Usage\u00b6","text":"<p>You can customize the BLAST search parameters:</p>"},{"location":"usage/clustalo/","title":"Multiple Sequence Alignment with Clustal Omega","text":"In\u00a0[13]: Copied! <pre># change log level to INFO\nimport sys\n\nfrom loguru import logger\n\nfrom pyeed import Pyeed\nfrom pyeed.model import Protein\nfrom pyeed.tools.clustalo import ClustalOmega\n\nlogger.remove()\nlevel = logger.add(sys.stderr, level=\"INFO\")\n</pre> # change log level to INFO import sys  from loguru import logger  from pyeed import Pyeed from pyeed.model import Protein from pyeed.tools.clustalo import ClustalOmega  logger.remove() level = logger.add(sys.stderr, level=\"INFO\") In\u00a0[14]: Copied! <pre># Initialize ClustalOmega\nclustalo = ClustalOmega()\n\n# Example sequences\nsequences = {\n    \"seq1\": \"AKFVMPDRAWHLYTGNECSKQRLYVWFHDGAPILKTQSDNMGAYRCPLFHVTKNWEI\",\n    \"seq2\": \"AKFVMPDRQWHLYTGQECSKQRLYVWFHDGAPILKTQSDNMGAYRCPLFHVTKNWEI\",\n    \"seq3\": \"AKFVMPDRQWHLYTGNECSKQRLYVWFHDGAPILKTQADNMGAYRCALFHVTK\",\n}\n\n# Perform alignment\nalignment = clustalo.align(sequences)\nprint(\"Aligned sequences:\")\nprint(alignment)\n</pre> # Initialize ClustalOmega clustalo = ClustalOmega()  # Example sequences sequences = {     \"seq1\": \"AKFVMPDRAWHLYTGNECSKQRLYVWFHDGAPILKTQSDNMGAYRCPLFHVTKNWEI\",     \"seq2\": \"AKFVMPDRQWHLYTGQECSKQRLYVWFHDGAPILKTQSDNMGAYRCPLFHVTKNWEI\",     \"seq3\": \"AKFVMPDRQWHLYTGNECSKQRLYVWFHDGAPILKTQADNMGAYRCALFHVTK\", }  # Perform alignment alignment = clustalo.align(sequences) print(\"Aligned sequences:\") print(alignment) <pre>Aligned sequences:\nseq1  AKFVMPDRAWHLYTGNECSKQRLYVWFHDGAPILKTQSDNMGAYRCPLFHVTKNWEI\nseq2  AKFVMPDRQWHLYTGQECSKQRLYVWFHDGAPILKTQSDNMGAYRCPLFHVTKNWEI\nseq3  AKFVMPDRQWHLYTGNECSKQRLYVWFHDGAPILKTQADNMGAYRCALFHVTK----\n</pre> In\u00a0[15]: Copied! <pre># Connect to database\npyeed = Pyeed(uri=\"bolt://129.69.129.130:7687\", user=\"neo4j\", password=\"12345678\")\n\n# Get protein IDs from database\naccession_ids = [protein.accession_id for protein in Protein.nodes.all()][:10]\n\n# Align sequences from database\nalignment = clustalo.align_from_db(accession_ids, pyeed.db)\nprint(\"Database alignment:\")\nprint(alignment)\n</pre> # Connect to database pyeed = Pyeed(uri=\"bolt://129.69.129.130:7687\", user=\"neo4j\", password=\"12345678\")  # Get protein IDs from database accession_ids = [protein.accession_id for protein in Protein.nodes.all()][:10]  # Align sequences from database alignment = clustalo.align_from_db(accession_ids, pyeed.db) print(\"Database alignment:\") print(alignment) <pre>Pyeed Graph Object Mapping constraints not defined. Use _install_labels() to set up model constraints.\n\ud83d\udce1 Connected to database.\nDatabase alignment:\nAAP20891.1      MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\nCAJ85677.1      MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDKLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\nSAQ02853.1      MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDKLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVKYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGASERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\nCDR98216.1      MSIQHFRVALIPFFAAFCFPVFAHPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVKYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDRWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGASERGSRGIIAALGPDGKPSRIVVIYMTGSQATMDERNRQIAEIGASLIKHW\nWP_109963600.1  MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDSWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGTGKRGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\nCAA41038.1      MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVKYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDHWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\nWP_109874025.1  MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDKLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDSWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\nCAA46344.1      MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDKLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVKYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDSWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGASERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\nAPG33178.1      MSIQHFRVALIPFFAAFCFPVFAHPETLVKVKDAEDQLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVKYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDSWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYMTGSQATMDERNRQIAEIGASLIKHW\nAKC98298.1      MSIQHFRVALIPFFAAFCLPVFAHPETLVKVKDAEDKLGARVGYIELDLNSGKILESFRPEERFPMMSTFKVLLCGAVLSRVDAGQEQLGRRIHYSQNDLVEYSPVTEKHLTDGMTVRELCSAAITMSDNTAANLLLTTIGGPKELTAFLHNMGDHVTRLDHWEPELNEAIPNDERDTTMPAAMATTLRKLLTGELLTLASRQQLIDWMEADKVAGPLLRSALPAGWFIADKSGAGERGSRGIIAALGPDGKPSRIVVIYTTGSQATMDERNRQIAEIGASLIKHW\n</pre>"},{"location":"usage/clustalo/#multiple-sequence-alignment-with-clustal-omega","title":"Multiple Sequence Alignment with Clustal Omega\u00b6","text":"<p>PyEED provides a convenient interface to Clustal Omega for multiple sequence alignment. This notebook demonstrates how to:</p> <ol> <li>Align sequences from a dictionary</li> <li>Align sequences directly from the database</li> </ol>"},{"location":"usage/clustalo/#direct-sequence-alignment","title":"Direct Sequence Alignment\u00b6","text":"<p>You can align sequences directly by providing a dictionary of sequences:</p>"},{"location":"usage/clustalo/#database-based-alignment","title":"Database-based Alignment\u00b6","text":"<p>You can also align sequences directly from the database by providing a list of accession IDs:</p>"},{"location":"usage/clustalo/#understanding-alignment-results","title":"Understanding Alignment Results\u00b6","text":"<p>The alignment result is a <code>MultipleSequenceAlignment</code> object with:</p> <ul> <li>List of <code>Sequence</code> objects</li> <li>Each sequence has an ID and aligned sequence</li> <li>Gaps are represented by '-' characters</li> <li>Sequences are padded to equal length</li> </ul> <p>The alignment preserves sequence order and maintains sequence IDs from the input.</p>"},{"location":"usage/clustalo/#configuration","title":"Configuration\u00b6","text":"<p>ClustalOmega requires the PyEED Docker service to be running. Make sure to:</p> <ol> <li>Have Docker installed</li> <li>Start the service with <code>docker-compose up -d</code></li> <li>The service runs on port 5001 by default</li> </ol>"},{"location":"usage/embedding_different_models/","title":"Protein Embedding with different models","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom loguru import logger\n\nfrom pyeed import Pyeed\nfrom pyeed.embeddings import get_processor\n\nfrom sklearn.decomposition import PCA\n\nlogger.remove()\nlevel = logger.add(sys.stderr, level=\"ERROR\")\n</pre> import matplotlib.pyplot as plt import sys import numpy as np import pandas as pd from loguru import logger  from pyeed import Pyeed from pyeed.embeddings import get_processor  from sklearn.decomposition import PCA  logger.remove() level = logger.add(sys.stderr, level=\"ERROR\") <pre>2025-05-29 12:01:28.282 | INFO     | pyeed.embeddings.processor:_initialize_devices:44 - Initialized 3 GPU device(s): [device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2)]\n</pre> In\u00a0[2]: Copied! <pre>uri = \"bolt://129.69.129.130:7688\"\nuser = \"neo4j\"\npassword = \"12345678\"\n\needb = Pyeed(uri, user=user, password=password)\needb.db.wipe_database(date='2025-05-29')\n</pre> uri = \"bolt://129.69.129.130:7688\" user = \"neo4j\" password = \"12345678\"  eedb = Pyeed(uri, user=user, password=password) eedb.db.wipe_database(date='2025-05-29') <pre>Pyeed Graph Object Mapping constraints not defined. Use _install_labels() to set up model constraints.\n\ud83d\udce1 Connected to database.\nAll data has been wiped from the database.\n</pre> In\u00a0[3]: Copied! <pre># these are example ids\ndf = pd.read_csv(\"resources/data_example.csv\", delimiter=\";\")\nprint(\"The data has the following columns:\")\nprint(df.columns)\n\n# create a dict with protein_id_database as key and phenotype as value\ndict_data = dict(zip(df[\"protein_id_database\"], df[\"phenotype\"]))\ndata_ids = df[\"protein_id_database\"].tolist()\n</pre> # these are example ids df = pd.read_csv(\"resources/data_example.csv\", delimiter=\";\") print(\"The data has the following columns:\") print(df.columns)  # create a dict with protein_id_database as key and phenotype as value dict_data = dict(zip(df[\"protein_id_database\"], df[\"phenotype\"])) data_ids = df[\"protein_id_database\"].tolist() <pre>The data has the following columns:\nIndex(['protein_name', 'phenotype', 'protein_id', 'protein_id_database'], dtype='object')\n</pre> In\u00a0[4]: Copied! <pre># now fecth all of the proteins from the database\needb.fetch_from_primary_db(data_ids, db=\"ncbi_protein\")\n</pre> # now fecth all of the proteins from the database eedb.fetch_from_primary_db(data_ids, db=\"ncbi_protein\") In\u00a0[5]: Copied! <pre>query = \"MATCH (p:Protein) WHERE p.accession_id IN $protein_ids RETURN p.accession_id, p.sequence\"\n\nresults = eedb.db.execute_read(query, parameters={\"protein_ids\": data_ids})\nsequences = [result[\"p.sequence\"] for result in results]\n\ndata = [(data_ids[i], sequences[i]) for i in range(len(data_ids))]\nprint(f\"First sequence (first 10 AA): {sequences[0][:10]} with length {len(sequences[0])} and id {data_ids[0]}\")\n</pre> query = \"MATCH (p:Protein) WHERE p.accession_id IN $protein_ids RETURN p.accession_id, p.sequence\"  results = eedb.db.execute_read(query, parameters={\"protein_ids\": data_ids}) sequences = [result[\"p.sequence\"] for result in results]  data = [(data_ids[i], sequences[i]) for i in range(len(data_ids))] print(f\"First sequence (first 10 AA): {sequences[0][:10]} with length {len(sequences[0])} and id {data_ids[0]}\") <pre>First sequence (first 10 AA): MSIQHFRVAL with length 286 and id AAP20891.1\n</pre> In\u00a0[6]: Copied! <pre>model_names = model_name_list = [\"esmc_300m\", \"facebook/esm2_t33_650M_UR50D\", 'prot_t5_xl_uniref50','facebook/esm2_t6_8M_UR50D']\n</pre> model_names = model_name_list = [\"esmc_300m\", \"facebook/esm2_t33_650M_UR50D\", 'prot_t5_xl_uniref50','facebook/esm2_t6_8M_UR50D'] In\u00a0[7]: Copied! <pre>processor = get_processor()\n\nfor model_name in model_names:\n    embeddings_per_residue = processor.calculate_batch_embeddings(data=data, model_name=model_name, embedding_type=\"last_hidden_state\", num_gpus=1)\n    if embeddings_per_residue is None:\n        continue\n\n    # convert mean embeddings to numpy array\n    embeddings = np.mean(np.array(embeddings_per_residue), axis=1)\n    print(f\"Embeddings shape: {embeddings.shape}\")\n    \n    # create PCA Plot from embeddings\n    pca = PCA(n_components=2)\n    pca.fit(embeddings)\n    embeddings_pca = pca.transform(embeddings)\n    plt.title(f\"PCA Plot of {model_name}\")\n    plt.xlabel(f\"PC1 with a variance of {pca.explained_variance_ratio_[0]:.2f}\")\n    plt.ylabel(f\"PC2 with a variance of {pca.explained_variance_ratio_[1]:.2f}\")\n    plt.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1])\n    plt.show()\n</pre> processor = get_processor()  for model_name in model_names:     embeddings_per_residue = processor.calculate_batch_embeddings(data=data, model_name=model_name, embedding_type=\"last_hidden_state\", num_gpus=1)     if embeddings_per_residue is None:         continue      # convert mean embeddings to numpy array     embeddings = np.mean(np.array(embeddings_per_residue), axis=1)     print(f\"Embeddings shape: {embeddings.shape}\")          # create PCA Plot from embeddings     pca = PCA(n_components=2)     pca.fit(embeddings)     embeddings_pca = pca.transform(embeddings)     plt.title(f\"PCA Plot of {model_name}\")     plt.xlabel(f\"PC1 with a variance of {pca.explained_variance_ratio_[0]:.2f}\")     plt.ylabel(f\"PC2 with a variance of {pca.explained_variance_ratio_[1]:.2f}\")     plt.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1])     plt.show() <pre>Fetching 4 files:   0%|          | 0/4 [00:00&lt;?, ?it/s]</pre> <pre>Embeddings shape: (68, 960)\n</pre> <pre>/home/nab/anaconda3/envs/pyeed_niklas_env/lib/python3.10/site-packages/transformers/modeling_utils.py:3437: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\nSome weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/home/nab/anaconda3/envs/pyeed_niklas_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1899: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n</pre> <pre>Embeddings shape: (68, 1280)\n</pre> <pre>/home/nab/anaconda3/envs/pyeed_niklas_env/lib/python3.10/site-packages/transformers/modeling_utils.py:3437: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n/home/nab/anaconda3/envs/pyeed_niklas_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1899: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\nYou are using the default legacy behaviour of the &lt;class 'transformers.models.t5.tokenization_t5.T5Tokenizer'&gt;. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n</pre> <pre>Embeddings shape: (68, 1024)\n</pre> <pre>/home/nab/anaconda3/envs/pyeed_niklas_env/lib/python3.10/site-packages/transformers/modeling_utils.py:3437: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\nSome weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/home/nab/anaconda3/envs/pyeed_niklas_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1899: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n</pre> <pre>Embeddings shape: (68, 320)\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"usage/embedding_different_models/#protein-embedding-with-different-models","title":"Protein Embedding with different models\u00b6","text":"<p>This notebook demonstrates how to calculate embeddings with different models.</p>"},{"location":"usage/embeddings_analysis/","title":"Protein Embedding Analysis Pipeline","text":"<p>This notebook demonstrates an end-to-end pipeline for protein embedding analysis. Here, we connect to a Neo4j database to fetch protein sequences from the NCBI protein database, compute high-dimensional embeddings using a pre-trained model, and then project these embeddings into two dimensions using t-SNE. The final visualization provides insights into the relationships among proteins based on their sequence properties.</p> In\u00a0[1]: Copied! <pre>import sys\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom loguru import logger\n\nfrom pyeed import Pyeed\nfrom pyeed.analysis.embedding_analysis import EmbeddingTool\n\n\nlogger.remove()\nlevel = logger.add(sys.stderr, level=\"ERROR\")\n</pre> import sys import matplotlib.pyplot as plt import numpy as np import pandas as pd from loguru import logger  from pyeed import Pyeed from pyeed.analysis.embedding_analysis import EmbeddingTool   logger.remove() level = logger.add(sys.stderr, level=\"ERROR\") <pre>2025-05-29 12:00:51.520 | INFO     | pyeed.embeddings.processor:_initialize_devices:44 - Initialized 3 GPU device(s): [device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2)]\n</pre> In\u00a0[2]: Copied! <pre>uri = \"bolt://129.69.129.130:7688\"\nuser = \"neo4j\"\npassword = \"12345678\"\n\needb = Pyeed(uri, user=user, password=password)\needb.db.wipe_database(date='2025-05-29')\n</pre> uri = \"bolt://129.69.129.130:7688\" user = \"neo4j\" password = \"12345678\"  eedb = Pyeed(uri, user=user, password=password) eedb.db.wipe_database(date='2025-05-29') <pre>Pyeed Graph Object Mapping constraints not defined. Use _install_labels() to set up model constraints.\n\ud83d\udce1 Connected to database.\nAll data has been wiped from the database.\n</pre> In\u00a0[3]: Copied! <pre>et = EmbeddingTool()\n</pre> et = EmbeddingTool() In\u00a0[4]: Copied! <pre># these are example ids\ndf = pd.read_csv(\"resources/data_example.csv\", delimiter=\";\")\nprint(\"The data has the following columns:\")\nprint(df.columns)\n\n# create a dict with protein_id_database as key and phenotype as value\ndict_data = dict(zip(df[\"protein_id_database\"], df[\"phenotype\"]))\n</pre> # these are example ids df = pd.read_csv(\"resources/data_example.csv\", delimiter=\";\") print(\"The data has the following columns:\") print(df.columns)  # create a dict with protein_id_database as key and phenotype as value dict_data = dict(zip(df[\"protein_id_database\"], df[\"phenotype\"])) <pre>The data has the following columns:\nIndex(['protein_name', 'phenotype', 'protein_id', 'protein_id_database'], dtype='object')\n</pre> In\u00a0[5]: Copied! <pre># now fecth all of the proteins from the database\needb.fetch_from_primary_db(df[\"protein_id_database\"].tolist(), db=\"ncbi_protein\")\n</pre> # now fecth all of the proteins from the database eedb.fetch_from_primary_db(df[\"protein_id_database\"].tolist(), db=\"ncbi_protein\") In\u00a0[6]: Copied! <pre>eedb.calculate_sequence_embeddings(model_name=\"esmc_300m\", embedding_type=\"final_embeddings\", num_gpus=3)\n</pre> eedb.calculate_sequence_embeddings(model_name=\"esmc_300m\", embedding_type=\"final_embeddings\", num_gpus=3) <pre>Fetching 4 files:   0%|          | 0/4 [00:00&lt;?, ?it/s]</pre> <pre>Fetching 4 files:   0%|          | 0/4 [00:00&lt;?, ?it/s]</pre> <pre>Fetching 4 files:   0%|          | 0/4 [00:00&lt;?, ?it/s]</pre> In\u00a0[12]: Copied! <pre># get the dimensions of the embeddings get one protein and then get the dimensions of the embedding\n# any random protein will do\nquery = \"MATCH (p:Protein) RETURN p.embedding LIMIT 20\"\nresult = eedb.db.execute_read(query)\ndimensions = np.array(result[10]['p.embedding']).shape\nprint(dimensions)\n</pre> # get the dimensions of the embeddings get one protein and then get the dimensions of the embedding # any random protein will do query = \"MATCH (p:Protein) RETURN p.embedding LIMIT 20\" result = eedb.db.execute_read(query) dimensions = np.array(result[10]['p.embedding']).shape print(dimensions)  <pre>(960,)\n</pre> In\u00a0[13]: Copied! <pre># get all of the data from embedding\nembedding_tool = EmbeddingTool()\nprotein_ids, embeddings_2d, labels, colors = (\n    embedding_tool.calculate_2d_projection_tsne(\n        db=eedb.db,\n        ids_list=df[\"protein_id_database\"].tolist(),\n        perplexity=1,\n        n_iter=3000,\n        ids_list_labels=dict_data,\n    )\n)\nprint(len(protein_ids))\n\nlabels_already_plotted = []\n\n# create a scatter plot for each unique label\nfor i in range(len(protein_ids)):\n    if labels[i] not in labels_already_plotted:\n        plt.scatter(\n            embeddings_2d[i, 0],\n            embeddings_2d[i, 1],\n            alpha=0.7,\n            s=50,\n            edgecolor=\"k\",\n            color=colors[i],\n            label=labels[i],\n        )\n        labels_already_plotted.append(labels[i])\n    else:\n        plt.scatter(\n            embeddings_2d[i, 0],\n            embeddings_2d[i, 1],\n            alpha=0.7,\n            s=50,\n            edgecolor=\"k\",\n            color=colors[i],\n        )\nplt.title(\"2D t-SNE Visualization of Protein Embeddings\")\nplt.xlabel(\"t-SNE Dimension 1\")\nplt.ylabel(\"t-SNE Dimension 2\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> # get all of the data from embedding embedding_tool = EmbeddingTool() protein_ids, embeddings_2d, labels, colors = (     embedding_tool.calculate_2d_projection_tsne(         db=eedb.db,         ids_list=df[\"protein_id_database\"].tolist(),         perplexity=1,         n_iter=3000,         ids_list_labels=dict_data,     ) ) print(len(protein_ids))  labels_already_plotted = []  # create a scatter plot for each unique label for i in range(len(protein_ids)):     if labels[i] not in labels_already_plotted:         plt.scatter(             embeddings_2d[i, 0],             embeddings_2d[i, 1],             alpha=0.7,             s=50,             edgecolor=\"k\",             color=colors[i],             label=labels[i],         )         labels_already_plotted.append(labels[i])     else:         plt.scatter(             embeddings_2d[i, 0],             embeddings_2d[i, 1],             alpha=0.7,             s=50,             edgecolor=\"k\",             color=colors[i],         ) plt.title(\"2D t-SNE Visualization of Protein Embeddings\") plt.xlabel(\"t-SNE Dimension 1\") plt.ylabel(\"t-SNE Dimension 2\") plt.legend() plt.tight_layout() plt.show() <pre>68\n</pre> In\u00a0[9]: Copied! <pre># this is the simple way to find the closest matches it loads all proteins into memory\n# so this is not the best way to do this for large datasets\n# on very small datasets it is still fine though, and works easily\n\nresults = et.find_closest_matches_simple(\n    start_sequence_id=df[\"protein_id_database\"].tolist()[0],\n    db=eedb.db,\n    metric=\"cosine\",\n    n=10,\n)\n\nprint(f\"Resulst for index {df['protein_id_database'].tolist()[0]} are:\")\nprint(results)\n</pre> # this is the simple way to find the closest matches it loads all proteins into memory # so this is not the best way to do this for large datasets # on very small datasets it is still fine though, and works easily  results = et.find_closest_matches_simple(     start_sequence_id=df[\"protein_id_database\"].tolist()[0],     db=eedb.db,     metric=\"cosine\",     n=10, )  print(f\"Resulst for index {df['protein_id_database'].tolist()[0]} are:\") print(results) <pre>Resulst for index AAP20891.1 are:\n[('AAP20891.1', 0.0), ('AGQ50511.1', 0.00016200621801287785), ('ABB97007.1', 0.0001810048295400879), ('AFN21551.1', 0.00018909362988450695), ('CAC67290.1', 0.00021654775310264718), ('ADL13944.1', 0.0002567003210336427), ('AAK30619.1', 0.0002616398020808264), ('AAL29433.1', 0.0002646931927183793), ('ACJ43254.1', 0.0002669990760338914), ('ACB22021.1', 0.0002755243601859636)]\n</pre> In\u00a0[10]: Copied! <pre># the more complex was involes creating a vector index of the embeddings\n# the vector index math and implementation is provied by neo4j\n\n# here we drop the vector index\net.drop_vector_index(\n    db=eedb.db,\n    index_name=\"vector_index_Protein_embedding\",\n)\n# here we create the vector index\net.create_embedding_vector_index_neo4j(\n    db=eedb.db,\n    index_name=\"vector_index_Protein_embedding\",\n    similarity_function=\"cosine\",\n    dimensions=960,\n    m=16,\n    ef_construction=512,\n)\n</pre> # the more complex was involes creating a vector index of the embeddings # the vector index math and implementation is provied by neo4j  # here we drop the vector index et.drop_vector_index(     db=eedb.db,     index_name=\"vector_index_Protein_embedding\", ) # here we create the vector index et.create_embedding_vector_index_neo4j(     db=eedb.db,     index_name=\"vector_index_Protein_embedding\",     similarity_function=\"cosine\",     dimensions=960,     m=16,     ef_construction=512, ) In\u00a0[11]: Copied! <pre># here we use the vector index to find the closest matches\nresults = et.find_nearest_neighbors_based_on_vector_index(\n    db=eedb.db,\n    query_id=df[\"protein_id_database\"].tolist()[0],\n    index_name=\"vector_index_Protein_embedding\",\n    number_of_neighbors=10,\n)\n\nprint(results)\n</pre> # here we use the vector index to find the closest matches results = et.find_nearest_neighbors_based_on_vector_index(     db=eedb.db,     query_id=df[\"protein_id_database\"].tolist()[0],     index_name=\"vector_index_Protein_embedding\",     number_of_neighbors=10, )  print(results) <pre>Output()</pre> <pre></pre> <pre>[('AAP20891.1', 1.0), ('AGQ50511.1', 0.9999189376831055), ('ABB97007.1', 0.999909520149231), ('AFN21551.1', 0.9999054670333862), ('CAC67290.1', 0.9998918771743774), ('ADL13944.1', 0.9998717904090881), ('AAK30619.1', 0.9998692274093628), ('AAL29433.1', 0.9998676776885986), ('ACJ43254.1', 0.9998666048049927), ('CBX53726.1', 0.9998624920845032)]\n</pre>"},{"location":"usage/embeddings_analysis/#protein-embedding-analysis-pipeline","title":"Protein Embedding Analysis Pipeline\u00b6","text":"<p>This notebook demonstrates how to fetch protein data, calculate embeddings, and visualize protein relationships using t-SNE.</p>"},{"location":"usage/embeddings_analysis/#database-connection-and-setup","title":"Database Connection and Setup\u00b6","text":"<p>Now we'll connect to our Neo4j database and prepare it for new data by:</p> <ol> <li>Establishing a connection</li> <li>Wiping any existing data</li> <li>Removing old constraints</li> </ol>"},{"location":"usage/embeddings_analysis/#fetching-protein-data","title":"Fetching Protein Data\u00b6","text":"<p>We'll now fetch protein sequences from the NCBI protein database using a list of protein IDs.</p>"},{"location":"usage/embeddings_analysis/#calculate-sequence-embeddings","title":"Calculate Sequence Embeddings\u00b6","text":"<p>Now we'll convert our protein sequences into numerical representations (embeddings) using a pre-trained model.</p>"},{"location":"usage/embeddings_analysis/#visualization-with-t-sne","title":"Visualization with t-SNE\u00b6","text":"<p>Finally, we'll project our high-dimensional embeddings into 2D space using t-SNE and create a visualization. The resulting plot will show how proteins relate to each other in terms of their sequence properties.</p>"},{"location":"usage/embeddings_analysis/#protein-embedding-search-methods","title":"Protein Embedding Search Methods\u00b6","text":"<p>There are two main approaches implemented for searching similar proteins using embeddings:</p>"},{"location":"usage/embeddings_analysis/#1-simple-search-method","title":"1. Simple Search Method\u00b6","text":"<p>The simple method (<code>find_closest_matches_simple</code>) loads all embeddings into memory to calculate distances. While straightforward, it's best suited for smaller datasets:</p>"},{"location":"usage/embeddings_analysis/#advantages","title":"Advantages:\u00b6","text":"<ul> <li>Simple implementation</li> <li>Works well for small datasets</li> <li>Flexible distance metrics</li> </ul>"},{"location":"usage/embeddings_analysis/#limitations","title":"Limitations:\u00b6","text":"<ul> <li>Memory intensive for large datasets</li> <li>Slower for large-scale searches</li> <li>Not scalable for production use with big databases</li> </ul>"},{"location":"usage/embeddings_analysis/#2-vector-index-search","title":"2. Vector Index Search\u00b6","text":"<p>The vector index method uses Neo4j's native vector indexing capabilities (HNSW algorithm) for efficient similarity search. This is the recommended approach for larger datasets and production use.</p>"},{"location":"usage/embeddings_analysis/#setting-up-the-vector-index","title":"Setting up the Vector Index:\u00b6","text":""},{"location":"usage/embeddings_analysis/#parameters-explained","title":"Parameters Explained:\u00b6","text":"<ul> <li><p><code>dimensions</code>: The size of your embedding vectors</p> <ul> <li>Use 960 for ESM-C model</li> <li>Use 1280 for ESM-2 model</li> </ul> </li> <li><p><code>m</code> (default=16): Maximum number of connections per node in the HNSW graph</p> <ul> <li>Higher values = better accuracy but slower indexing</li> <li>Lower values = faster indexing but potentially less accurate</li> <li>Recommended range: 5-100</li> </ul> </li> <li><p><code>ef_construction</code> (default=512): Controls index quality during construction</p> <ul> <li>Higher values = better quality but slower indexing</li> <li>Lower values = faster indexing but potentially lower quality</li> <li>Recommended range: 100-1000</li> </ul> </li> </ul>"},{"location":"usage/embeddings_analysis/#searching-with-the-vector-index","title":"Searching with the Vector Index:\u00b6","text":""},{"location":"usage/embeddings_analysis/#advantages-of-vector-index","title":"Advantages of Vector Index:\u00b6","text":"<ul> <li>Highly efficient for large datasets</li> <li>Optimized for high-dimensional data</li> <li>Scales well with database size</li> <li>Maintains good performance with growing data</li> </ul>"},{"location":"usage/embeddings_analysis/#important-notes","title":"Important Notes:\u00b6","text":"<ol> <li><p>The vector index needs time to populate after creation. The code automatically waits and shows a progress bar during population.</p> </li> <li><p>The similarity scores returned by the vector index search are:</p> <ul> <li>For cosine similarity: Range [-1 to 1], where 1 is most similar</li> <li>For euclidean similarity: Lower values indicate more similarity</li> </ul> </li> <li><p>The index is persistent in the database and only needs to be created once, unless you want to change its parameters.</p> </li> <li><p>Memory usage is optimized as the index handles the heavy lifting instead of loading all embeddings into memory.</p> </li> </ol> <p>For most production use cases, the vector index method is recommended as it provides the best balance of performance and scalability.</p>"},{"location":"usage/initial_setup/","title":"Initial Setup","text":"In\u00a0[2]: Copied! <pre>from pyeed import Pyeed\n\nuri = \"bolt://127.0.0.1:7687\"\nuser = \"neo4j\"\npassword = \"12345678\"\n\n# Create a Pyeed object, automatically connecting to the database\needb = Pyeed(uri, user, password)\n\n# Disconnect from the database\needb.db.close()\n</pre> from pyeed import Pyeed  uri = \"bolt://127.0.0.1:7687\" user = \"neo4j\" password = \"12345678\"  # Create a Pyeed object, automatically connecting to the database eedb = Pyeed(uri, user, password)  # Disconnect from the database eedb.db.close() <pre>\ud83d\udce1 Connected to database.\n\ud83d\udd0c Connection closed.\n</pre> In\u00a0[\u00a0]: Copied! <pre># Initialize the database constraints\needb.db.initialize_db_constraints()\n\n# Remove all database constraints\needb.db.remove_db_constraints()\n</pre> # Initialize the database constraints eedb.db.initialize_db_constraints()  # Remove all database constraints eedb.db.remove_db_constraints()"},{"location":"usage/initial_setup/#initial-setup","title":"Initial Setup\u00b6","text":"<p>After the a local or hosted Neo4j database is setup, the next step is to connect to the database via <code>pyeed</code>.</p>"},{"location":"usage/initial_setup/#connect-and-disconnect-database","title":"Connect and Disconnect database\u00b6","text":"<p>Connection to the database is established via the <code>Pyeed</code> class, orchestrating all operations on the database.</p>"},{"location":"usage/initial_setup/#set-and-remove-database-constraints","title":"Set and remove database constraints\u00b6","text":"<p>Graph databases are \"schema optional\". However, constraints can be set to enforce data integrity. To set the constraints of the pyeed graph model use the <code>initialize_db_constraints</code> method. By default constraints are set based on the pyeed graph model. If a custom <code>neomodel</code> model is used, the path to the corresponding file, outlining the graph model must be provided.</p> <p>Defining the constraints ensures that some properties are unique and that some properties are mandatory. Furthermore, vector indices are created for the properties that are used for searching.</p> <p>The constraint only need to be set once.</p>"},{"location":"usage/mmseqs/","title":"Clustering with MMSeqs2","text":"In\u00a0[1]: Copied! <pre>from pyeed import Pyeed\nfrom pyeed.model import Protein\nfrom pyeed.tools.mmseqs import MMSeqs\n</pre> from pyeed import Pyeed from pyeed.model import Protein from pyeed.tools.mmseqs import MMSeqs In\u00a0[3]: Copied! <pre># Example sequences (seq 4 and seq 5 are highly similar)\nsequence_dict = {\n    \"seq1\": \"MGAWQPLIRKSTFNVADCEYLMKQHTGYPWVRESDTAHKLQNVGICFPYQAMTNYLG\",\n    \"seq2\": \"QVLATPRWDKEFYHMSNCGRILQAVPTKDYFSHGRWMNEKAPTYLQSDVCHAFGKLT\",\n    \"seq3\": \"DLNQWPKYARHTMGSLVEFACRQNIYTDHKPLWYGVSMEAFDQTCKPRYNLHGIVKT\",\n    \"seq4\": \"AKFVMPDRQWHLYTGNECSKQRLYVWFYDGAPILKTQSDNMGAYRCPLFHVTKNWEI\",\n    \"seq5\": \"AKFVMPDRQWHLYTGNECSKQRLYVWFHDGAPILKTQSDNMGAYRCPLFHVTKNWEI\",\n}\n\n# Initialize MMSeqs with custom parameters\nmmseqs = MMSeqs(\n    min_seq_id=0.8,  # 80% sequence identity threshold\n    coverage=0.8,  # 80% coverage required\n    cov_mode=0,  # Bidirectional coverage mode\n)\n\n# Perform clustering\nclusters = mmseqs.cluster_sequence_dict(sequence_dict)\nprint(\"Clustering results:\")\nfor cluster in clusters:\n    print(f\"\\nCluster representative: {cluster.representative_id}\")\n    print(f\"Cluster members: {cluster.represented_ids}\")\n</pre> # Example sequences (seq 4 and seq 5 are highly similar) sequence_dict = {     \"seq1\": \"MGAWQPLIRKSTFNVADCEYLMKQHTGYPWVRESDTAHKLQNVGICFPYQAMTNYLG\",     \"seq2\": \"QVLATPRWDKEFYHMSNCGRILQAVPTKDYFSHGRWMNEKAPTYLQSDVCHAFGKLT\",     \"seq3\": \"DLNQWPKYARHTMGSLVEFACRQNIYTDHKPLWYGVSMEAFDQTCKPRYNLHGIVKT\",     \"seq4\": \"AKFVMPDRQWHLYTGNECSKQRLYVWFYDGAPILKTQSDNMGAYRCPLFHVTKNWEI\",     \"seq5\": \"AKFVMPDRQWHLYTGNECSKQRLYVWFHDGAPILKTQSDNMGAYRCPLFHVTKNWEI\", }  # Initialize MMSeqs with custom parameters mmseqs = MMSeqs(     min_seq_id=0.8,  # 80% sequence identity threshold     coverage=0.8,  # 80% coverage required     cov_mode=0,  # Bidirectional coverage mode )  # Perform clustering clusters = mmseqs.cluster_sequence_dict(sequence_dict) print(\"Clustering results:\") for cluster in clusters:     print(f\"\\nCluster representative: {cluster.representative_id}\")     print(f\"Cluster members: {cluster.represented_ids}\") <pre>Output()</pre> <pre></pre> <pre>Clustering results:\n\nCluster representative: seq1\nCluster members: ['seq1']\n\nCluster representative: seq2\nCluster members: ['seq2']\n\nCluster representative: seq3\nCluster members: ['seq3']\n\nCluster representative: seq5\nCluster members: ['seq5', 'seq4']\n</pre> In\u00a0[7]: Copied! <pre># Connect to database\npyeed = Pyeed(uri=\"bolt://localhost:7687\", user=\"neo4j\", password=\"12345678\")\n\n# Get first 100 protein IDs from database\naccession_ids = [protein.accession_id for protein in Protein.nodes.all()][:100]\n\n# Cluster sequences\nclusters = mmseqs.cluster_from_db(accession_ids, pyeed.db)\nprint(f\"Found {len(clusters)} clusters\")\n</pre> # Connect to database pyeed = Pyeed(uri=\"bolt://localhost:7687\", user=\"neo4j\", password=\"12345678\")  # Get first 100 protein IDs from database accession_ids = [protein.accession_id for protein in Protein.nodes.all()][:100]  # Cluster sequences clusters = mmseqs.cluster_from_db(accession_ids, pyeed.db) print(f\"Found {len(clusters)} clusters\") <pre>\ud83d\udce1 Connected to database.\nFound 34 clusters\n</pre> In\u00a0[8]: Copied! <pre>mmseqs = MMSeqs(\n    # Sequence identity and coverage\n    min_seq_id=0.5,  # 50% sequence identity threshold\n    coverage=0.8,  # 80% coverage required\n    # Coverage mode\n    cov_mode=0,  # 0: bidirectional, 1: query, 2: target\n    # Performance settings\n    threads=4,  # Number of CPU threads\n    sensitivity=7.5,  # 1.0 (fast) to 9.0 (sensitive)\n    # Clustering behavior\n    cluster_mode=0,  # 0: set-cover, 1: connected-component, 2: greedy\n    seq_id_mode=0,  # 0: alignment length, 1: shorter sequence\n    rescore_mode=0,  # Whether to rescore overlapping alignments\n)\n\n# The parameters affect both clustering methods\nclusters = mmseqs.cluster_sequence_dict(sequence_dict)\n# or\nclusters = mmseqs.cluster_from_db(accession_ids, pyeed.db)\n</pre> mmseqs = MMSeqs(     # Sequence identity and coverage     min_seq_id=0.5,  # 50% sequence identity threshold     coverage=0.8,  # 80% coverage required     # Coverage mode     cov_mode=0,  # 0: bidirectional, 1: query, 2: target     # Performance settings     threads=4,  # Number of CPU threads     sensitivity=7.5,  # 1.0 (fast) to 9.0 (sensitive)     # Clustering behavior     cluster_mode=0,  # 0: set-cover, 1: connected-component, 2: greedy     seq_id_mode=0,  # 0: alignment length, 1: shorter sequence     rescore_mode=0,  # Whether to rescore overlapping alignments )  # The parameters affect both clustering methods clusters = mmseqs.cluster_sequence_dict(sequence_dict) # or clusters = mmseqs.cluster_from_db(accession_ids, pyeed.db)"},{"location":"usage/mmseqs/#clustering-with-mmseqs2","title":"Clustering with MMSeqs2\u00b6","text":"<p>For clustering, please make sure that the pyeed Docker container with MMSeqs2 is running.</p> <p>PyEED provides a convenient interface to MMSeqs2 for sequence clustering. This notebook demonstrates how to use the MMSeqs class for:</p> <ol> <li>Clustering sequences from a dictionary</li> <li>Clustering sequences directly from the database</li> </ol>"},{"location":"usage/mmseqs/#direct-sequence-clustering","title":"Direct Sequence Clustering\u00b6","text":"<p>You can cluster sequences directly by providing a dictionary of sequences:</p>"},{"location":"usage/mmseqs/#clustering-from-database","title":"Clustering from Database\u00b6","text":"<p>You can also cluster sequences directly from the PyEED database:</p>"},{"location":"usage/mmseqs/#customizing-mmseqs-parameters","title":"Customizing MMSeqs Parameters\u00b6","text":"<p>MMSeqs offers several parameters to control clustering behavior:</p>"},{"location":"usage/mmseqs/#understanding-cluster-results","title":"Understanding Cluster Results\u00b6","text":"<p>Each cluster is represented by a <code>Cluster</code> object with two attributes:</p> <ul> <li><code>representative_id</code>: The sequence chosen as the cluster representative</li> <li><code>represented_ids</code>: List of all sequences in the cluster (including the representative)</li> </ul> <p>Sequences with high similarity (based on <code>min_seq_id</code> and <code>coverage</code>) will be grouped together.</p>"},{"location":"usage/mutation_analysis/","title":"Mutation Analysis","text":"In\u00a0[5]: Copied! <pre>import sys\n\nfrom loguru import logger\n\nfrom pyeed import Pyeed\nfrom pyeed.analysis.mutation_detection import MutationDetection\nfrom pyeed.analysis.standard_numbering import StandardNumberingTool\n\nlogger.remove()\nlevel = logger.add(sys.stderr, level=\"WARNING\")\n</pre> import sys  from loguru import logger  from pyeed import Pyeed from pyeed.analysis.mutation_detection import MutationDetection from pyeed.analysis.standard_numbering import StandardNumberingTool  logger.remove() level = logger.add(sys.stderr, level=\"WARNING\") <ul> <li><code>Pyeed</code>: Main class for interacting with the PyEED database</li> <li><code>MutationDetection</code>: Class for identifying differences between protein sequences</li> <li><code>StandardNumberingTool</code>: Ensures consistent position numbering across different protein sequences</li> </ul> In\u00a0[9]: Copied! <pre>uri = \"bolt://129.69.129.130:7687\"\nuser = \"neo4j\"\npassword = \"12345678\"\n\needb = Pyeed(uri, user=user, password=password)\n\needb.db.wipe_database(date=\"2025-05-16\")\n</pre> uri = \"bolt://129.69.129.130:7687\" user = \"neo4j\" password = \"12345678\"  eedb = Pyeed(uri, user=user, password=password)  eedb.db.wipe_database(date=\"2025-05-16\") <pre>\ud83d\udce1 Connected to database.\nAll data has been wiped from the database.\n</pre> <ol> <li>Establishes connection parameters to a local Neo4j database</li> <li>Creates a PyEED instance with these credentials</li> <li>Wipes existing database data (with date \"2025-01-19\")</li> <li>Removes all database constraints for a fresh start</li> </ol> <p>This ensures we're working with a clean database state.</p> In\u00a0[10]: Copied! <pre>ids = [\"AAM15527.1\", \"AAF05614.1\", \"AFN21551.1\", \"CAA76794.1\", \"AGQ50511.1\"]\n\needb.fetch_from_primary_db(ids, db=\"ncbi_protein\")\needb.fetch_dna_entries_for_proteins()\needb.create_coding_sequences_regions()\n</pre> ids = [\"AAM15527.1\", \"AAF05614.1\", \"AFN21551.1\", \"CAA76794.1\", \"AGQ50511.1\"]  eedb.fetch_from_primary_db(ids, db=\"ncbi_protein\") eedb.fetch_dna_entries_for_proteins() eedb.create_coding_sequences_regions() <ol> <li>Defines two protein sequence IDs to analyze</li> <li>Fetches these sequences from NCBI's protein database</li> <li>All sequences are beta-lactamase proteins</li> <li>The sequences are automatically parsed and stored in the Neo4j database</li> <li>Additional metadata like organism information and CDS (Coding Sequence) details are also stored</li> </ol> In\u00a0[11]: Copied! <pre>sn_protein = StandardNumberingTool(name=\"test_standard_numbering_protein\")\n\n\nsn_protein.apply_standard_numbering(\n    base_sequence_id=\"AAM15527.1\", db=eedb.db, list_of_seq_ids=ids\n)\n\nsn_dna = StandardNumberingTool(name=\"test_standard_numbering_dna_pairwise\")\n\nquery_get_region_ids = \"\"\"\nMATCH (p:Protein)&lt;-[rel:ENCODES]-(d:DNA)-[rel2:HAS_REGION]-&gt;(r:Region)\nWHERE r.annotation = $region_annotation AND p.accession_id IN $protein_id\nRETURN id(r)\n\"\"\"\n\nregion_ids = eedb.db.execute_read(\n    query_get_region_ids,\n    parameters={\"protein_id\": ids, \"region_annotation\": \"coding sequence\"},\n)\nregion_ids = [id[\"id(r)\"] for id in region_ids]\nprint(f\"Region ids: {region_ids}\")\nprint(f\"len of ids: {len(ids)}\")\n\nsn_dna.apply_standard_numbering_pairwise(\n    base_sequence_id=\"AF190695.1\",\n    db=eedb.db,\n    node_type=\"DNA\",\n    region_ids_neo4j=region_ids,\n)\n</pre> sn_protein = StandardNumberingTool(name=\"test_standard_numbering_protein\")   sn_protein.apply_standard_numbering(     base_sequence_id=\"AAM15527.1\", db=eedb.db, list_of_seq_ids=ids )  sn_dna = StandardNumberingTool(name=\"test_standard_numbering_dna_pairwise\")  query_get_region_ids = \"\"\" MATCH (p:Protein)&lt;-[rel:ENCODES]-(d:DNA)-[rel2:HAS_REGION]-&gt;(r:Region) WHERE r.annotation = $region_annotation AND p.accession_id IN $protein_id RETURN id(r) \"\"\"  region_ids = eedb.db.execute_read(     query_get_region_ids,     parameters={\"protein_id\": ids, \"region_annotation\": \"coding sequence\"}, ) region_ids = [id[\"id(r)\"] for id in region_ids] print(f\"Region ids: {region_ids}\") print(f\"len of ids: {len(ids)}\")  sn_dna.apply_standard_numbering_pairwise(     base_sequence_id=\"AF190695.1\",     db=eedb.db,     node_type=\"DNA\",     region_ids_neo4j=region_ids, ) <pre>Output()</pre> <pre>Region ids: [849, 843, 848, 842, 847, 841, 846, 839, 850, 844]\nlen of ids: 5\nNumber of existing pairs: 0\nNumber of total pairs: 4\nNumber of pairs to align: 4\n</pre> <pre></pre> <ol> <li>Creates a new StandardNumberingTool instance named \"test_standard_numbering\"</li> <li>Uses KJO56189.1 as the reference sequence for numbering</li> <li>Performs multiple sequence alignment (MSA) using CLUSTAL</li> <li>The alignment output shows:<ul> <li>Asterisks (*) indicate identical residues</li> <li>Colons (:) indicate conserved substitutions</li> <li>Periods (.) indicate semi-conserved substitutions</li> </ul> </li> <li>This step is crucial for ensuring mutations are correctly identified relative to consistent positions</li> </ol> In\u00a0[12]: Copied! <pre>md = MutationDetection()\n\nseq1 = \"AAM15527.1\"\nseq2 = \"AAF05614.1\"\nname_of_standard_numbering_tool = \"test_standard_numbering_protein\"\n\nmutations_protein = md.get_mutations_between_sequences(\n    seq1, seq2, eedb.db, name_of_standard_numbering_tool\n)\n</pre> md = MutationDetection()  seq1 = \"AAM15527.1\" seq2 = \"AAF05614.1\" name_of_standard_numbering_tool = \"test_standard_numbering_protein\"  mutations_protein = md.get_mutations_between_sequences(     seq1, seq2, eedb.db, name_of_standard_numbering_tool ) In\u00a0[13]: Copied! <pre>md = MutationDetection()\n\n\nseq1 = \"AF190695.1\"\nseq2 = \"JX042489.1\"\nname_of_standard_numbering_tool = \"test_standard_numbering_dna_pairwise\"\n\nmutations_dna = md.get_mutations_between_sequences(\n    seq1,\n    seq2,\n    eedb.db,\n    name_of_standard_numbering_tool,\n    node_type=\"DNA\",\n    region_ids_neo4j=region_ids,\n)\n</pre> md = MutationDetection()   seq1 = \"AF190695.1\" seq2 = \"JX042489.1\" name_of_standard_numbering_tool = \"test_standard_numbering_dna_pairwise\"  mutations_dna = md.get_mutations_between_sequences(     seq1,     seq2,     eedb.db,     name_of_standard_numbering_tool,     node_type=\"DNA\",     region_ids_neo4j=region_ids, ) <ol> <li>Creates a MutationDetection instance</li> <li>Compares the two sequences using the standard numbering scheme</li> <li>Identifies all positions where amino acids differ</li> <li>Automatically saves the mutations to the database</li> <li>Returns a dictionary containing mutation information</li> </ol> In\u00a0[14]: Copied! <pre>print(mutations_protein)\n\n\n# remove double realtionship, there are many doubles between the same DNA and the same Organismen\n# just keep the first one and remove the rest\nquery_remove_double_relationship = \"\"\"\nMATCH (d:DNA {accession_id: 'KT405476.1'})-[r:ORIGINATES_FROM]-(e)\nWITH d, r, e\nORDER BY id(r)\nLIMIT 1\nDELETE r\n\"\"\"\n</pre> print(mutations_protein)   # remove double realtionship, there are many doubles between the same DNA and the same Organismen # just keep the first one and remove the rest query_remove_double_relationship = \"\"\" MATCH (d:DNA {accession_id: 'KT405476.1'})-[r:ORIGINATES_FROM]-(e) WITH d, r, e ORDER BY id(r) LIMIT 1 DELETE r \"\"\"   <pre>{'from_positions': [241, 272, 125], 'to_positions': [241, 272, 125], 'from_monomers': ['R', 'D', 'V'], 'to_monomers': ['S', 'N', 'I']}\n</pre> <p>Outputs a detailed mutation map showing:</p> <ul> <li><code>from_positions</code>: [102, 162, 236] - Where mutations occur in the sequence</li> <li><code>to_positions</code>: [102, 162, 236] - Corresponding positions in the second sequence</li> <li><code>from_monomers</code>: ['E', 'S', 'G'] - Original amino acids</li> <li><code>to_monomers</code>: ['K', 'R', 'S'] - Mutated amino acids</li> </ul> <p>This means we found three mutations:</p> <ol> <li>Position 102: Glutamic acid (E) \u2192 Lysine (K)</li> <li>Position 162: Serine (S) \u2192 Arginine (R)</li> <li>Position 236: Glycine (G) \u2192 Serine (S)</li> </ol> In\u00a0[15]: Copied! <pre>for i in range(len(mutations_dna[\"from_positions\"])):\n    print(\n        f\"Mutation on position {mutations_dna['from_positions'][i]} -&gt; {mutations_dna['to_positions'][i]} with a nucleotide change of {mutations_dna['from_monomers'][i]} -&gt; {mutations_dna['to_monomers'][i]}\"\n    )\n</pre> for i in range(len(mutations_dna[\"from_positions\"])):     print(         f\"Mutation on position {mutations_dna['from_positions'][i]} -&gt; {mutations_dna['to_positions'][i]} with a nucleotide change of {mutations_dna['from_monomers'][i]} -&gt; {mutations_dna['to_monomers'][i]}\"     ) <pre>Mutation on position 474 -&gt; 474 with a nucleotide change of T -&gt; C\nMutation on position 199 -&gt; 199 with a nucleotide change of C -&gt; A\nMutation on position 138 -&gt; 138 with a nucleotide change of A -&gt; G\nMutation on position 18 -&gt; 18 with a nucleotide change of T -&gt; C\nMutation on position 396 -&gt; 396 with a nucleotide change of T -&gt; G\nMutation on position 721 -&gt; 721 with a nucleotide change of A -&gt; C\nMutation on position 706 -&gt; 706 with a nucleotide change of G -&gt; A\nMutation on position 717 -&gt; 717 with a nucleotide change of G -&gt; A\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"usage/mutation_analysis/#mutation-analysis","title":"Mutation Analysis\u00b6","text":"<p>Mutations between sequences can be comprehensively analyzed.</p>"},{"location":"usage/mutation_analysis/#sequence-retrieval","title":"Sequence Retrieval\u00b6","text":""},{"location":"usage/mutation_analysis/#apply-standard-numbering","title":"Apply Standard Numbering\u00b6","text":""},{"location":"usage/mutation_analysis/#mutation-detection","title":"Mutation Detection\u00b6","text":""},{"location":"usage/mutation_analysis/#results","title":"Results\u00b6","text":""},{"location":"usage/network_analysis/","title":"Network Analysis","text":"In\u00a0[1]: Copied! <pre>import sys\n\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom loguru import logger\n\nfrom pyeed import Pyeed\nfrom pyeed.analysis.network_analysis import NetworkAnalysis\nfrom pyeed.analysis.sequence_alignment import PairwiseAligner\n\nlogger.remove()\nlevel = logger.add(sys.stderr, level=\"WARNING\")\n</pre> import sys  import matplotlib.pyplot as plt import networkx as nx from loguru import logger  from pyeed import Pyeed from pyeed.analysis.network_analysis import NetworkAnalysis from pyeed.analysis.sequence_alignment import PairwiseAligner  logger.remove() level = logger.add(sys.stderr, level=\"WARNING\") In\u00a0[2]: Copied! <pre>uri = \"bolt://127.0.0.1:7688\"\nuser = \"neo4j\"\npassword = \"12345678\"\n\needb = Pyeed(uri, user=user, password=password)\n</pre> uri = \"bolt://127.0.0.1:7688\" user = \"neo4j\" password = \"12345678\"  eedb = Pyeed(uri, user=user, password=password) <pre>Pyeed Graph Object Mapping constraints not defined. Use _install_labels() to set up model constraints.\n\ud83d\udce1 Connected to database.\n</pre> In\u00a0[5]: Copied! <pre># load NCBI accession ids from a file\nids = []\nwith open(\"ids.txt\", \"r\") as f:\n    for line in f:\n        ids.append(line.strip())\n\n\n# now fecth all of the proteins from the database\needb.fetch_from_primary_db(ids, db=\"ncbi_protein\")\n</pre> # load NCBI accession ids from a file ids = [] with open(\"ids.txt\", \"r\") as f:     for line in f:         ids.append(line.strip())   # now fecth all of the proteins from the database eedb.fetch_from_primary_db(ids, db=\"ncbi_protein\") In\u00a0[7]: Copied! <pre># perform the sequence alignment\npa = PairwiseAligner()\nalignments = pa.align_multipairwise(ids=ids, db=eedb.db)\n</pre> # perform the sequence alignment pa = PairwiseAligner() alignments = pa.align_multipairwise(ids=ids, db=eedb.db) <pre>Output()</pre> <pre></pre> In\u00a0[8]: Copied! <pre>attribute = \"similarity\"\nscale = 1\nthreshold = 0.15\nmode = \"HIDE_UNDER_THRESHOLD\"\ntype_relationship = \"PAIRWISE_ALIGNED\"\n</pre> attribute = \"similarity\" scale = 1 threshold = 0.15 mode = \"HIDE_UNDER_THRESHOLD\" type_relationship = \"PAIRWISE_ALIGNED\" In\u00a0[11]: Copied! <pre>na = NetworkAnalysis(db=eedb.db)\nnetwork = na.create_graph(ids=ids, nodes=[\"Protein\"])\n</pre> na = NetworkAnalysis(db=eedb.db) network = na.create_graph(ids=ids, nodes=[\"Protein\"]) In\u00a0[12]: Copied! <pre>filtered_graph, pos = na.calculate_positions_2d(\n    attribute=attribute,\n    scale=scale,\n    threshold=threshold,\n    mode=mode,\n    type_relationship=type_relationship,\n)\n</pre> filtered_graph, pos = na.calculate_positions_2d(     attribute=attribute,     scale=scale,     threshold=threshold,     mode=mode,     type_relationship=type_relationship, ) In\u00a0[16]: Copied! <pre>node_labels = {\n    n: data[\"properties\"].get(\"accession_id\", n)\n    for n, data in filtered_graph.nodes(data=True)\n}\n\nedge_weights = nx.get_edge_attributes(filtered_graph, attribute) if attribute else {}\n\n\n# Draw edge labels if attribute is provided\nif attribute:\n    nx.draw_networkx_edge_labels(filtered_graph, pos, edge_labels=edge_weights)\n\nnx.draw(\n    filtered_graph,\n    pos,\n    with_labels=True,\n    node_size=550,\n    alpha=0.8,\n    font_size=8,\n    edge_color=\"black\",\n    labels=node_labels,\n)\n\nplt.title(\"Example network of pairwise aligned proteins\")\n\nplt.show()\n</pre> node_labels = {     n: data[\"properties\"].get(\"accession_id\", n)     for n, data in filtered_graph.nodes(data=True) }  edge_weights = nx.get_edge_attributes(filtered_graph, attribute) if attribute else {}   # Draw edge labels if attribute is provided if attribute:     nx.draw_networkx_edge_labels(filtered_graph, pos, edge_labels=edge_weights)  nx.draw(     filtered_graph,     pos,     with_labels=True,     node_size=550,     alpha=0.8,     font_size=8,     edge_color=\"black\",     labels=node_labels, )  plt.title(\"Example network of pairwise aligned proteins\")  plt.show()"},{"location":"usage/standard_numbering/","title":"Standard numbering","text":"In\u00a0[19]: Copied! <pre>%reload_ext autoreload\n%autoreload 2\nimport sys\n\nfrom loguru import logger\n\nfrom pyeed import Pyeed\nfrom pyeed.analysis.standard_numbering import StandardNumberingTool\n\nlogger.remove()\nlevel = logger.add(sys.stderr, level=\"WARNING\")\n</pre> %reload_ext autoreload %autoreload 2 import sys  from loguru import logger  from pyeed import Pyeed from pyeed.analysis.standard_numbering import StandardNumberingTool  logger.remove() level = logger.add(sys.stderr, level=\"WARNING\") In\u00a0[20]: Copied! <pre>uri = \"bolt://129.69.129.130:7687\"\nuser = \"neo4j\"\npassword = \"12345678\"\n\needb = Pyeed(uri, user=user, password=password)\needb.db.wipe_database(date=\"2025-03-19\")\n\needb.db.initialize_db_constraints(user=user, password=password)\n</pre> uri = \"bolt://129.69.129.130:7687\" user = \"neo4j\" password = \"12345678\"  eedb = Pyeed(uri, user=user, password=password) eedb.db.wipe_database(date=\"2025-03-19\")  eedb.db.initialize_db_constraints(user=user, password=password) <pre>\ud83d\udce1 Connected to database.\nAll data has been wiped from the database.\nthe connection url is bolt://neo4j:12345678@129.69.129.130:7687\nLoaded /home/nab/Niklas/pyeed/src/pyeed/model.py\nConnecting to bolt://neo4j:12345678@129.69.129.130:7687\nSetting up indexes and constraints...\n\nFound model.StrictStructuredNode\n ! Skipping class model.StrictStructuredNode is abstract\nFound model.Organism\n + Creating node unique constraint for taxonomy_id on label Organism for class model.Organism\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=12, name='constraint_unique_Organism_taxonomy_id', type='UNIQUENESS', schema=(:Organism {taxonomy_id}), ownedIndex=5 )'.}\nFound model.Site\n + Creating node unique constraint for site_id on label Site for class model.Site\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=14, name='constraint_unique_Site_site_id', type='UNIQUENESS', schema=(:Site {site_id}), ownedIndex=7 )'.}\nFound model.Region\n + Creating node unique constraint for region_id on label Region for class model.Region\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=19, name='constraint_unique_Region_region_id', type='UNIQUENESS', schema=(:Region {region_id}), ownedIndex=11 )'.}\nFound model.CatalyticActivity\n + Creating node unique constraint for catalytic_id on label CatalyticActivity for class model.CatalyticActivity\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=3, name='constraint_unique_CatalyticActivity_catalytic_id', type='UNIQUENESS', schema=(:CatalyticActivity {catalytic_id}), ownedIndex=15 )'.}\nFound model.StandardNumbering\n + Creating node unique constraint for name on label StandardNumbering for class model.StandardNumbering\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=16, name='constraint_unique_StandardNumbering_name', type='UNIQUENESS', schema=(:StandardNumbering {name}), ownedIndex=20 )'.}\nFound model.GOAnnotation\n + Creating node unique constraint for go_id on label GOAnnotation for class model.GOAnnotation\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=10, name='constraint_unique_GOAnnotation_go_id', type='UNIQUENESS', schema=(:GOAnnotation {go_id}), ownedIndex=4 )'.}\nFound model.Protein\n + Creating node unique constraint for accession_id on label Protein for class model.Protein\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=24, name='constraint_unique_Protein_accession_id', type='UNIQUENESS', schema=(:Protein {accession_id}), ownedIndex=13 )'.}\n + Creating vector index for embedding on label Protein for class model.Protein\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent index already exists, 'Index( id=9, name='vector_index_Protein_embedding', type='VECTOR', schema=(:Protein {embedding}), indexProvider='vector-2.0' )'.}\nFound model.DNA\n + Creating node unique constraint for accession_id on label DNA for class model.DNA\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=8, name='constraint_unique_DNA_accession_id', type='UNIQUENESS', schema=(:DNA {accession_id}), ownedIndex=21 )'.}\n + Creating vector index for embedding on label DNA for class model.DNA\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent index already exists, 'Index( id=6, name='vector_index_DNA_embedding', type='VECTOR', schema=(:DNA {embedding}), indexProvider='vector-2.0' )'.}\nFound model.OntologyObject\n + Creating node unique constraint for name on label OntologyObject for class model.OntologyObject\n{code: Neo.ClientError.Schema.EquivalentSchemaRuleAlreadyExists} {message: An equivalent constraint already exists, 'Constraint( id=17, name='constraint_unique_OntologyObject_name', type='UNIQUENESS', schema=(:OntologyObject {name}), ownedIndex=23 )'.}\n\nFinished 10 classes.\n\u2705 Databse constraints and indexes set up according to Pyeed Graph Object Model.\n</pre> In\u00a0[21]: Copied! <pre>ids = [\"AAM15527.1\", \"AAF05614.1\", \"AFN21551.1\", \"CAA76794.1\", \"AGQ50511.1\"]\n\needb.fetch_from_primary_db(ids, db=\"ncbi_protein\")\needb.fetch_dna_entries_for_proteins()\needb.create_coding_sequences_regions()\n</pre> ids = [\"AAM15527.1\", \"AAF05614.1\", \"AFN21551.1\", \"CAA76794.1\", \"AGQ50511.1\"]  eedb.fetch_from_primary_db(ids, db=\"ncbi_protein\") eedb.fetch_dna_entries_for_proteins() eedb.create_coding_sequences_regions() In\u00a0[22]: Copied! <pre>sn = StandardNumberingTool(name=\"test_standard_numbering_pairwise\")\n\n\nsn.apply_standard_numbering_pairwise(\n    base_sequence_id=\"AAM15527.1\", db=eedb.db, list_of_seq_ids=ids[0:5]\n)\n</pre> sn = StandardNumberingTool(name=\"test_standard_numbering_pairwise\")   sn.apply_standard_numbering_pairwise(     base_sequence_id=\"AAM15527.1\", db=eedb.db, list_of_seq_ids=ids[0:5] ) <pre>Output()</pre> <pre></pre> In\u00a0[23]: Copied! <pre>sn.apply_standard_numbering_pairwise(\n    base_sequence_id=\"AAM15527.1\", db=eedb.db, list_of_seq_ids=ids\n)\n</pre> sn.apply_standard_numbering_pairwise(     base_sequence_id=\"AAM15527.1\", db=eedb.db, list_of_seq_ids=ids ) <pre>Output()</pre> <pre></pre> In\u00a0[24]: Copied! <pre>sn_clustal = StandardNumberingTool(name=\"test_standard_numbering_clustal\")\n\nsn_clustal.apply_standard_numbering(\n    base_sequence_id=\"AAM15527.1\", db=eedb.db, list_of_seq_ids=ids\n)\n</pre> sn_clustal = StandardNumberingTool(name=\"test_standard_numbering_clustal\")  sn_clustal.apply_standard_numbering(     base_sequence_id=\"AAM15527.1\", db=eedb.db, list_of_seq_ids=ids ) In\u00a0[25]: Copied! <pre>sn_dna = StandardNumberingTool(name=\"test_standard_numbering_dna\")\n\nsn_dna.apply_standard_numbering(\n    base_sequence_id=\"AF190695.1\", db=eedb.db, node_type=\"DNA\"\n)\n</pre> sn_dna = StandardNumberingTool(name=\"test_standard_numbering_dna\")  sn_dna.apply_standard_numbering(     base_sequence_id=\"AF190695.1\", db=eedb.db, node_type=\"DNA\" ) In\u00a0[26]: Copied! <pre>sn_dna_pairwise = StandardNumberingTool(name=\"test_standard_numbering_dna_pairwise\")\n\nsn_dna_pairwise.apply_standard_numbering_pairwise(\n    base_sequence_id=\"AF190695.1\", db=eedb.db, node_type=\"DNA\"\n)\n</pre> sn_dna_pairwise = StandardNumberingTool(name=\"test_standard_numbering_dna_pairwise\")  sn_dna_pairwise.apply_standard_numbering_pairwise(     base_sequence_id=\"AF190695.1\", db=eedb.db, node_type=\"DNA\" ) <pre>Output()</pre> <pre></pre> In\u00a0[27]: Copied! <pre>sn_dna_region = StandardNumberingTool(\n    name=\"test_standard_numbering_dna_pairwise_region\"\n)\n\n\nids = [\"AAM15527.1\", \"AAF05614.1\", \"AFN21551.1\", \"CAA76794.1\", \"AGQ50511.1\"]\n\n\nquery_get_region_ids = \"\"\"\nMATCH (p:Protein)&lt;-[rel:ENCODES]-(d:DNA)-[rel2:HAS_REGION]-&gt;(r:Region)\nWHERE r.annotation = $region_annotation AND p.accession_id IN $protein_id\nRETURN id(r)\n\"\"\"\n\nregion_ids = eedb.db.execute_read(\n    query_get_region_ids,\n    parameters={\"protein_id\": ids, \"region_annotation\": \"coding sequence\"},\n)\nregion_ids = [id[\"id(r)\"] for id in region_ids]\nprint(f\"Region ids: {region_ids}\")\nprint(f\"len of ids: {len(ids)}\")\n\n\nsn_dna_region.apply_standard_numbering_pairwise(\n    base_sequence_id=\"AF190695.1\",\n    db=eedb.db,\n    node_type=\"DNA\",\n    region_ids_neo4j=region_ids,\n)\n</pre> sn_dna_region = StandardNumberingTool(     name=\"test_standard_numbering_dna_pairwise_region\" )   ids = [\"AAM15527.1\", \"AAF05614.1\", \"AFN21551.1\", \"CAA76794.1\", \"AGQ50511.1\"]   query_get_region_ids = \"\"\" MATCH (p:Protein)&lt;-[rel:ENCODES]-(d:DNA)-[rel2:HAS_REGION]-&gt;(r:Region) WHERE r.annotation = $region_annotation AND p.accession_id IN $protein_id RETURN id(r) \"\"\"  region_ids = eedb.db.execute_read(     query_get_region_ids,     parameters={\"protein_id\": ids, \"region_annotation\": \"coding sequence\"}, ) region_ids = [id[\"id(r)\"] for id in region_ids] print(f\"Region ids: {region_ids}\") print(f\"len of ids: {len(ids)}\")   sn_dna_region.apply_standard_numbering_pairwise(     base_sequence_id=\"AF190695.1\",     db=eedb.db,     node_type=\"DNA\",     region_ids_neo4j=region_ids, ) <pre>Output()</pre> <pre>Region ids: [13, 0, 41, 38, 19]\nlen of ids: 5\n</pre> <pre></pre> <p>In both cases, there are now standard numbering nodes to all the proteins and they have on their edge the standradnumbering data.</p>"},{"location":"usage/standard_numbering/#standard-numbering","title":"Standard Numbering\u00b6","text":"<p>The standard numbering tool is used to number the residues of a protein sequence. It allows for comparison of different protein sequences by aligning them and numbering the residues in a common reference frame.</p> <p>It can be run in two different modes:</p> <ol> <li>Pairwise alignment: This mode aligns two sequences and numbers the residues in a common reference frame. Here a base sequence is provided and the other sequences are aligned to it.</li> <li>Clustal alignment: This mode aligns a sequence against a multiple sequence alignment and numbers the residues in a common reference frame. Here a base sequence is provided and the other sequences are aligned to it.</li> </ol>"}]}